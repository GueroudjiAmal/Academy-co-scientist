—Understanding performance and provenance of
task-based workflows poses significant challenges, particularly in
distributed configurations where resources are shared by multiple
applications. Task-based workflow management systems further
complicate performance predictability because of their dynam-
icity that subtly alters task execution order from run to run. In
this paper we propose a layered characterization framework for
performance and task provenance for Dask.distributed workflows
running on high-performance computing (HPC) platforms. It
collects data from jobs, the workflow management system, and
the operating system to aid in understanding the performance
of these workflows. Our approach encompasses three main
contributions: first, an extension of Dask.distributed to capture
high-fidelity task provenance using Mochi data services; second,
the adaptation of the established HPC I/O characterization tool
Darshan to gather high-fidelity I/O data, thereby enhancing the
granularity of our analysis; and third, a framework to combine
and process the collected data and provide helpful insights into
performance characterization and reproducibility, alongside our
lessons learned.
Index Terms—High-performance computing (HPC), task-based
workflows, performance characterization, performance variabil-
ity, provenance, performance reproducibility, Dask
I. I NTRODUCTION
Scientific workflows executed on high-performance, het-
erogeneous computing environments rely on the complex
composition of system software, middleware services, and ap-
plication codes [1]. Pythonic task-based programming models
are increasingly prevalent for large-scale computations and
data-intensive processing because of their high productivity.
Examples of such tools include Parsl [2], Dask [3], and
RADICAL-Pilot [4].
In contrast to traditional MPI-based workflows, which are
predominantly static in nature and where the tasks assigned to
each MPI process are known in advance, task-based workflows
are dynamically scheduled. These workflows rely on a runtime
scheduler to efficiently orchestrate resources within a single
application. Scheduling decisions are made transparently and
dynamically as the workflow progresses, and tasks are dis-
patched to available resources at runtime, resulting in a lack
of a priori information regarding the specific tasks that each
worker will execute. While this approach to resource manage-
ment hides the complexity of the underlying infrastructure and
the resource/task management from users, it also obscures a
potential source of eventual performance variability.
Reproducibility, defined as the ability to reliably recreate
the same results, outputs, or behaviors from a given set of in-
puts, configurations, and conditions [5], encounters significant
challenges in computational sciences because of complicating
factors such as non-deterministic ordering of floating-point
operations, parallel executions, workflow patterns, and job
scheduling.
In this paper we study Dask workflows to identify task
behavior, performance, and provenance to determine which
tasks, task behaviors, and system characteristics are respon-
sible for the largest variations during multiple executions of
the same set of codes in the same configurations. We use
these performance variability measures to help us determine
the sources of overall irreproducibility in distributed workflow
performance. In particular, we aim to answer the following
research questions in this work:
1) What workflow management system (WMS) capabilities
are required to extract this information?
2) What information from a dynamically scheduled work-
flow is required to characterize performance variations?
3) What correlations between tasks and events would help
us investigate performance variability and understand the
sources of latency and irreproducible performance?
4) Can we identify gaps in the metadata collection?
This work addresses these questions for Dask workflows
by collecting data from different layers and tools and storing
the data in a common tabular format with shared identifiers
between the different sources, facilitating compliance with
FAIR principles [6], especially interoperability and reusability.
Our contributions include the following:
• Data collection at the WMS level: we extend
Dask.distributed to extract high-fidelity task provenance
by leveraging a Mochi HPC [7] event streaming service
known as Mofka. This enables us to track the detailed
lineage and execution history of individual tasks without
perturbing the workflow system.
• Data collection at the I/O level and correlation with task
data: we adapt the well-established HPC I/O characteriza-
2032979-8-3503-5554-3/24/$31.00 ©2024 IEEE
DOI 10.1109/SCW63240.2024.00254
SC24-W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis | 979-8-3503-5554-3/24/$31.00 ©2024 IEEE | DOI: 10.1109/SCW63240.2024.00254
Authorized licensed use limited to: Argonne National Laboratory. Downloaded on September 17,2025 at 20:48:28 UTC from IEEE Xplore.  Restrictions apply. 
tion tool Darshan [8] to gather more granular performance
data including detailed insights into task execution, in-
cluding I/O behavior, with thread-level fidelity.
• Analysis framework: we introduce a framework for dis-
secting and understanding the performance dynamics of
Dask.distributed workflows.
• Lessons learned: we discuss the challenges and lessons
learned in this study and identify additional metadata that
needs to be collected to explain the gaps.
The remainder of this paper is organized as follows. In
Section II we summarize related work, and in Section III
we present our proposed implementation with Dask, Dar-
shan, and Mofka. Section III-E discusses provenance and
metadata extraction, and Section IV proposes an evaluation
including analysis and visualization. In Section V we discuss
the challenges and lessons learned during our investigationIn
Section VI we summarize our conclusions and briefly discuss
ideas for future work.
II. R ELATED WORK
Many HPC performance profiling tools are available to aid
in understanding and optimizing the performance of scientific
applications [9], [10]. Although these tools are highly effective
across a wide range of applications, they do not include
native workflow support. Specifically, they do not present tasks
as distinct entities from threads or processes, nor do they
understand the specifics of task execution in a WMS, since
these vary by implementation. Thus, it is difficult for these
tools to map from low-level performance counters to specific
tasks and dependencies, which is crucial for understanding
these workflows.
Several task-based workflows offer their own integrated
performance profiling tools tailored to the WMS they operate
within. However, these tools often lack integration with other
profilers or performance characterization tools, limiting their
versatility and interoperability. For example, Dask [3] provides
a comprehensive dashboard for diagnostics, including task
progress, bytes stored by workers, CPU utilization, and other
relevant metrics, but this capability is available only to Dask
workflows. Similarly to Dask, Ray [11] offers a web-based
dashboard with a rich set of data and plots about cluster
utilization and resource status, node count and status, and
running tasks. Ray also introduces the capability to filter
logs using Loki,1 enhancing workflow behavior understanding.
Pegasus [12] provides information about the running workflow
and job statistics, integrity metrics (checksum), task status and
data, and a notification system for both job and workflows.
Despite the richness of data provided by these tools, ex-
tracting and processing this information for further analysis,
such as performance reproducibility studies or correlation with
data from other tools, remain challenging because the collected
data is often specific to each workflow system. This limitation
underscores the need for improved interoperability and data
exchange mechanisms across different performance profiling
1https://github.com/grafana/loki
tools and between different layers. Reconciling data sources
from heterogeneous services (e.g., mapping from low-level
performance counters to specific workflow tasks) is a nontriv-
ial step required for analysis and is not resolved with these
tools. Before improving the reproducibility of performance
in HPC workflows, one needs to be able to measure it at a
low level of task or function granularity instead of aggregate
statistics, as is commonly done with current performance tools.
This work addresses these challenges for Dask workflows by
collecting data from different layers and tools and storing the
data in a common tabular format, facilitating compliance with
FAIR principles, especially interoperability and reusability.
III. P ROPOSED IMPLEMENTATION
In this paper we focus on studying the performance and the
provenance of Dask.distributed workflows while running on
HPC platforms. Nevertheless, our approach can be used for
other workflow management systems and tools.
A. Dask.distributed workflows
Dask.distributed [3] is a distributed task-based framework
and WMS known for its versatility and productivity. It offers
multiple approaches to writing programs, ranging from uti-
lizing lower-level decorators and futures for task creation to
leveraging higher-level distributed interfaces for well-known
libraries such as NumPy, pandas, and Scikit-learn. In Dask, a
task is essentially a function that executes within a distributed
process known as a worker, and a workflow is described as
a directed acyclic graph, where nodes are tasks and edges
are task dependencies. A typical Dask cluster comprises three
primary entities: (a) the client is responsible for creating and
submitting tasks to a runtime scheduler; (b) the scheduler
orchestrates tasks within the cluster, dispatching tasks to avail-
able workers and managing their exe